{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR \n",
    "\n",
    "# Add freeze_support for multiprocessing\n",
    "if __name__ == '__main__':\n",
    "    torch.multiprocessing.freeze_support()\n",
    "\n",
    "# Define the neural network architecture with increased depth\n",
    "class DeepNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(256 * 4 * 4, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 256 * 4 * 4)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Rest of the code remains the same\n",
    "\n",
    "# Initialize the network, loss function, and optimizer\n",
    "net = DeepNet()  # Use the deeper network\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9)\n",
    "# scheduler = StepLR(optimizer, step_size=30, gamma=0.1)  # Adjust the step_size and gamma as needed\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)  # Use Adam optimizer\n",
    "scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "# # Load CIFAR-10 dataset\n",
    "# transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "# Define data augmentation transformations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
    "    transforms.RandomCrop(32, padding=4),  # Randomly crop images with padding\n",
    "    transforms.ToTensor(),  # Convert images to tensors\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize the image data\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset with data augmentation\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize and train multiple models\n",
    "num_models = 3\n",
    "models = [DeepNet() for _ in range(num_models)]\n",
    "criterions = [nn.CrossEntropyLoss() for _ in range(num_models)]\n",
    "optimizers = [optim.Adam(model.parameters(), lr=0.001) for model in models]\n",
    "\n",
    "num_epochs = 5\n",
    "ensemble_train_loss_values = []\n",
    "ensemble_train_acc_values = []\n",
    "ensemble_test_loss_values = []\n",
    "ensemble_test_acc_values = []\n",
    "\n",
    "for model_id, (model, criterion, optimizer) in enumerate(zip(models, criterions, optimizers)):\n",
    "    train_loss_values = []\n",
    "    train_acc_values = []\n",
    "    test_loss_values = []\n",
    "    test_acc_values = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "        train_loss_values.append(running_loss / len(trainloader))\n",
    "        train_acc_values.append(100 * correct / total)\n",
    "    \n",
    "        # Test the model\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "    \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "    \n",
    "        test_loss_values.append(test_loss / len(testloader))\n",
    "        test_acc_values.append(100 * correct / total)\n",
    "    \n",
    "        print(f\"Model {model_id + 1}, Epoch {epoch + 1}/{num_epochs}: \"\n",
    "              f\"Train Loss = {train_loss_values[-1]:.4f}, Train Acc = {train_acc_values[-1]:.2f}%, \"\n",
    "              f\"Test Loss = {test_loss_values[-1]:.4f}, Test Acc = {test_acc_values[-1]:.2f}%\")\n",
    "    \n",
    "    # Save training and test metrics for this model\n",
    "    ensemble_train_loss_values.append(train_loss_values)\n",
    "    ensemble_train_acc_values.append(train_acc_values)\n",
    "    ensemble_test_loss_values.append(test_loss_values)\n",
    "    ensemble_test_acc_values.append(test_acc_values)\n",
    "\n",
    "# Combine predictions using majority voting\n",
    "def ensemble_predict(models, dataloader):\n",
    "    predictions = []\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        model_predictions = []\n",
    "        with torch.no_grad():\n",
    "            for data in dataloader:\n",
    "                images, _ = data\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                model_predictions.extend(predicted.tolist())\n",
    "        predictions.append(model_predictions)\n",
    "    return predictions\n",
    "\n",
    "# Make predictions using the ensemble of models on the test dataset\n",
    "test_predictions = ensemble_predict(models, testloader)\n",
    "\n",
    "# Combine predictions using majority voting\n",
    "final_predictions = []\n",
    "for i in range(len(test_predictions[0])):\n",
    "    votes = [test_predictions[j][i] for j in range(len(models))]\n",
    "    majority_vote = max(set(votes), key=votes.count)\n",
    "    final_predictions.append(majority_vote)\n",
    "\n",
    "# Calculate the ensemble test accuracy\n",
    "correct = sum(1 for p, t in zip(final_predictions, testset.targets) if p == t)\n",
    "ensemble_test_accuracy = correct / len(testset)\n",
    "print(f\"Ensemble Test Accuracy: {ensemble_test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Plotting training and test metrics for each model\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(num_models):\n",
    "    plt.subplot(2, num_models, i + 1)\n",
    "    plt.plot(range(num_epochs), ensemble_train_loss_values[i], label=f'Model {i + 1}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Training Loss')\n",
    "    plt.legend()\n",
    "    plt.title(f'Model {i + 1} Training Loss')\n",
    "    \n",
    "    plt.subplot(2, num_models, num_models + i + 1)\n",
    "    plt.plot(range(num_epochs), ensemble_test_acc_values[i], label=f'Model {i + 1}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Test Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title(f'Model {i + 1} Test Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
